---
title: "Prepping the data"
output: html_document
---

```{r}
library(tidyverse)
library(lubridate)
library(RSocrata)
library(tsfknn)
```


```{r}
df_first <- read.socrata(
  "https://data.cityofnewyork.us/resource/ebb7-mvp5.json",
  # app_token = "YOURAPPTOKENHERE",
  # email     = "user@example.com",
  # password  = "fakepassword"
)
```

### Some numeric columns are stored as characters. We also need to turn the month into a POSIXCT()


```{r}
df_first$month <- lubridate::parse_date_time(df_first$month, "%y / %m")
```

```{r}
which(sapply(df_first, function(x) is.character(x))) #STUDY THIS
```

I don't know why the Socrata API is storing them as characters, when the data on the website is storing them as numbers. For now we can keep communitydistrict and borough_id as characters and convert them to integers later

```{r}
cols_num_floats <- c(4:6,8:11)
df_first[cols_num_floats] <- sapply(df_first[cols_num_floats], as.numeric)
#sapply(df_first, class) it worked
cols_num_ints <- c(3,7)
df_first[cols_num_ints] <- sapply(df_first[cols_num_ints], as.integer)
sapply(df_first, class)
```
### Create copies of the dataframe

```{r}
DSNY <- df_first
```


##Questions to answer:

* How many variables will be worked with?
* How many years worth of waste data is sufficient enough for training, testing and validating sets of data?
 + For now, our training data should fall from 2005 through 2020, with the testing data being 2021
* Which boroughs will be studied?
* Which districts will be studied?
* If working with timeseries models, ensure your variable of interest is turned into a ts object. Research the needed frequency and start dates with this data, as we are looking into monthly waste management values.

```{r}
DSNY_second <- DSNY %>% filter(month >= as.Date("2005-01-01") & month < as.Date("2021-01-01"))
```

```{r}
#Default borough, unless specified is the Bronx
#default communitydistrict is 01
DSNY_second %>% 
  group_by(borough, communitydistrict) %>% 
  slice(-(1:12))
```
```{r}
DSNY_second %>% 
  slice(n() -19:0)
```

Run the code chunk below when you have decided on all the necessary variables that can be created and used on the DSNY data

```{r}
# DSNY_validation <- DSNY %>% filter(month >= as.Date("2021-01-01") & month <= as.Date("2021-12-01"))
```

## Attempting to aggregate the waste streams into one borough


```{r}
DSNY_second <-DSNY_second %>%
  mutate(total_waste = select(.,4:6) %>% rowSums(na.rm = TRUE)) # could also use refusetonscollected:mgptonscollected
```


```{r}
DSNY_second %>% 
  group_by(borough) %>% 
  summarise(., sum(total_waste))
```

```{r}
DSNY_third <- DSNY_second %>% 
  group_by(month, borough) %>% 
  summarise(., total_waste = sum(total_waste)) %>% 
  arrange(borough)
```

### Great success!!!

## Getting total waste, by community district, per month

```{r}
DSNY_second %>% 
  group_by(month,borough,communitydistrict) %>% 
  summarise(., total_waste = sum(total_waste)) %>% 
  arrange(communitydistrict)
```

It turns out this approach is no different from the DSNY_second data-frame. The totalwaste per communitydistrict, per month was already calculated. 

Here below is what the dataframe would look like when filtered for BK01

```{r}
DSNY_second %>% 
  filter(borough == "Brooklyn" & communitydistrict == 1) %>%
  group_by(month,borough,communitydistrict) %>% 
  summarise(., total_waste = sum(total_waste)) %>% 
  arrange(communitydistrict)
```

## Attempt to aggregate the waste streams as a NYC value

In doing this, we get single waste values per month. With the waste value representing the total of the three waste streams collected for NYC

```{r}
DSNY_third %>% group_by(month) %>% summarise(., total_waste2 = sum(total_waste))
```

## NYC DOE School Enrollment

Link for Open Data: https://data.cityofnewyork.us/browse?q=Enrollment%20Statistics%20by%20District&sortBy=relevance


```{r}
#https://dev.socrata.com/foundry/data.cityofnewyork.us/e649-r223
doe_first <- read.socrata(
  "https://data.cityofnewyork.us/resource/e649-r223.json",
  # app_token = "YOURAPPTOKENHERE",
  # email     = "user@example.com",
  # password  = "fakepassword"
)
```

```{r}
glimpse(doe_first)
```

We dont necessarily need to convert the year into a posixct. This represents a school year. I.e 2020-2021

My next goal is to explore how column sum or row sum will work on this data set. But first we need to convert the grades from characters to integers

```{r}
#doe_first <- doe_first_copy
doe_first_copy <- doe_first
doe_first[,4:19] <- lapply(doe_first[,4:19], as.integer)

#Line 90 will convert all the NA's in the integer columns into zeros
#doe_first %>% mutate_if(is.integer, function(x){ifelse(is.na(x), 0,x)})
# doe_first %>% 
#   summarise(across(doe_first[,4:19]), ~sum(., is.na(.), 0))

```
```{r}
doe_first %>% 
  mutate(across(doe_first[, 4:19], ~ sum(., is.na(.), 0)))
```

```{r}
doe_first %>% summarise(across(where(is.numeric), ~ sum(.x)))
```

```{r}
doe_first <- doe_first %>% 
  mutate(Total = select(., pk:se1) %>% rowSums(na.rm = TRUE))
```


```{r}
# doe_first %>% 
#   mutate(total_sum = summarise(across(where(is.numeric), ~ sum(.x))))
```

```{r}
glimpse(doe_first)
```


## Getting US Holidays

```{r}
# holidays_dataset_2017 <- read.socrata(
#   "https://date.nager.at/api/v3/publicholidays/2017/AT.json",
#   # app_token = "YOURAPPTOKENHERE",
#   # email     = "user@example.com",
#   # password  = "fakepassword"
# )
```



```{r}
library(Holidays)
# isHoliday(x = 20210421) #fail
```
```{r, hide = TRUE, show = FALSE, warning=FALSE}
#install.packages("RQuantLib")
library("RQuantLib")
```

```{r}
?isBusinessDay
```

## Looking for Economic Data variables

https://fred.stlouisfed.org/tags/series?t=monthly%3Bprice%20index%3Busa&ob=pv&od=desc
https://fred.stlouisfed.org/series/UNRATE

## Getting started with censusapi

```{r}
library(censusapi)
library(tidycensus)
library(viridis)
```

```{r API key, warning=FALSE}
Sys.setenv(CENSUS_KEY = "741791920011136da47e8b205ca50942f4eb1ee0")
readRenviron("~/.Renviron")
Sys.getenv("CENSUS_KEY")
```

```{r}
apis <- listCensusApis()
View(apis)
```

```{r}
acs19 <- load_variables(year = 2019, dataset = 'acs5', cache = TRUE)
view(acs19)
```

```{r}
medval_md <- get_acs(geography = 'county', variables = 'B25077_001', state = 'MD', survey = 'acs5')
View(medval_md)
```

```{r}
medval_pgmd <- get_acs(geography = 'tract', variables = 'B25077_001', state = 'MD', county = 033, survey = 'acs5')
View(medval_pgmd)
```

```{r}
# no return values
#get_acs(year = 2019, geography = 'zcta', state = 'NY', zcta = '11369', variables = 'B08006_001', survey = 'acs1')

```

```{r}
get_acs(year = 2019, geography = 'zcta', state = 'NY', zcta = '11369', variables = 'B08006_001')
```

