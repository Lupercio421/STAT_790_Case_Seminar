---
title: "dynamic regression attempt"
author: "Daniel L."
date: "5/13/2022"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, results='hide', error=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(RSocrata)
library(tsfknn)
library(fpp3)
library(tsibble)
library(tseries)
library(feasts)
library(timetk)
library(modeltime)
library(readr)
library(zoo)
load("C:\\Users\\Daniel\\Desktop\\R\\STAT_790\\STAT_790_Case_Seminar\\dyna_regress_prep.Rdata")
```

# Auto-fit model

https://otexts.com/fpp3/regarima.html

The function ARIMA() will fit a regression model with ARIMA errors if exogenous regressors are included in the formula.

```{r}
auto_fit <- nyc_ts_2 %>% 
  model(ARIMA(tw_diff1 ~ cpi_diff1 + unemp_diff1 + avg_precip_diff1 + temp_diff1 + cdd_diff1))

report(auto_fit)
```

The model returns

## Auto-fit model with constant

```{r}
auto_fit_constant <- nyc_ts_2 %>% 
  model(ARIMA(tw_diff1 ~ 1 + cpi_diff1 + unemp_diff1 + avg_precip_diff1 + temp_diff1 + cdd_diff1))

report(auto_fit_constant)
```

### Regression Residuals of LM w/ ARIMA(5,0,0) errors

```{r}
bind_rows(
    `Regression residuals` =
        as_tibble(residuals(auto_fit_constant, type = "regression")),
    `ARIMA residuals` =
        as_tibble(residuals(auto_fit_constant, type = "innovation")),
    .id = "type"
  ) %>%
  mutate(
    type = factor(type, levels=c(
      "Regression residuals", "ARIMA residuals"))
  ) %>%
  ggplot(aes(x = month_num, y = .resid)) +
  geom_line() +
  facet_grid(vars(type)) + 
  labs(title = "Regression Residuals of LM w/ ARIMA(5,0,0) errors",
       subtitle = "01/2005 - 12/2020",
       x = "Month Number",
       y = "Residuals")
```

```{r}

```


```{r echo=FALSE, results='hide', error=FALSE, include=FALSE}
nyc_ts_2 %>% 
  group_by("Year" = year(month)) %>% 
  summarise(.,
            "Average Total Waste" = mean(total_waste_total))
```

#### KPSS Test for 'total_waste' 
\
$H_0: \text{The time series is trend stationary}$ vs $H_a: \text{The time series is not trend stationary}$

If the p-value of the test is less than some significance level (e.g. $\alpha = .05$) then we reject the null hypothesis and conclude that the time series is not trend stationary.

```{r kpss test}
#total waste values
nyc_ts_2 %>% features(total_waste_total, unitroot_kpss)

#differenced values
nyc_ts_2 %>% features(tw_diff1, unitroot_kpss)
```

According to the results of the KPSS test, we reject the $H_0$ when evaluating the total_waste values. We fail to reject the $H_0$ when evaluating the differenced values

```{r echo=FALSE, results='hide', error=FALSE, include=FALSE}
#precipitation values
nyc_ts_2 %>% features(avg_precip, unitroot_kpss)

#differenced precipitation values
nyc_ts_2 %>% features(avg_precip_diff1, unitroot_kpss)

#temperature values
nyc_ts_2 %>% features(avg_temp, unitroot_kpss)

#differenced temperature values
nyc_ts_2 %>% features(temp_diff1, unitroot_kpss)

#CDD values
nyc_ts_2 %>% features(avg_CDD, unitroot_kpss)

#differenced CDD values
nyc_ts_2 %>% features(cdd_diff1, unitroot_kpss)

#CPI values
nyc_ts_2 %>% features(cpi, unitroot_kpss) #this is not trend stationary

#differenced CPI values
nyc_ts_2 %>% features(cpi_diff1, unitroot_kpss)

#Unemployment rate values
nyc_ts_2 %>% features(unemp_rate, unitroot_kpss)

#differenced Unemployment rate values
nyc_ts_2 %>% features(unemp_diff1, unitroot_kpss)
```


```{r}
nyc_ts_2 %>% 
  ACF(total_waste_total, lag_max = 36) %>% 
  autoplot()

#acf of the differenced values
nyc_ts_2 %>% 
  ACF(tw_diff1, lag_max = 36) %>% 
  autoplot()
```

# Creating ARIMA models with zoo() and the arima package from stats()

```{r}
DSNY_NYC_zoo_ts <- ts(final_nyc_data_small[,2],
   start = as.yearmon(final_nyc_data_small$month)[1],
   frequency = 12)
# autoplot(as.zoo(DSNY_NYC_zoo_ts))
```

## $\text{ARIMA(0,0,0)}$ with constant
${ARIMA(0,0,0)}$

```{r}
nyc_arima000_fit_cons <- nyc_ts_2 %>% 
  model(arima000_constant = ARIMA(total_waste_total ~ 1 + pdq(0,0,0)))

zoo_arima000_fit <- arima(DSNY_NYC_zoo_ts, order = 1 + c(0,0,0))
res_arima000 <- zoo_arima000_fit$residuals
acf(res_arima000, lag.max = 36)
pacf(res_arima000, lag.max = 36)
accuracy(nyc_arima000_fit_cons)[4]
```

RMSE = 20560.3, The first significant lag in the ACF plot is lag 4. The first significant lag in the PACF plot is also lag 4. Both these lags are negative, which indicate the use of an MA() argument. The seasonal lags are once again present in both plots. In the PACF() plot, lag 8 is negative and significant.

## $\text{ARIMA(0,0,4)}$ with constant
${ARIMA(0,0,4)}$

```{r}
nyc_arima004_fit_cons <- nyc_ts_2 %>% 
  model(arima004_constant = ARIMA(total_waste_total ~ 1 + 
                                    pdq(0,0,4)))
        
zoo_arima004_fit <- arima(DSNY_NYC_zoo_ts, 
                          order = 1 + c(0,0,4))
#names(zoo_arima000_fit)
res_arima004 <- zoo_arima004_fit$residuals
acf(res_arima004, lag.max = 36)
pacf(res_arima004, lag.max = 36)
accuracy(nyc_arima004_fit_cons)[4]
```

RMSE = 17602.62. Seasonal lags worth exploring. In the PACF plot, lag = 9 is negatively autocorrelated and significant

## $\text{ARIMA(0,0,4)(1,0,0)}$ with constant and seasonal
$ARIMA(0,0,4)(1,0,0)_{12}$

```{r}
nyc_arima004_100_seasonal_fit_cons <- nyc_ts_2 %>% 
  model(arima004_100_constant = ARIMA(total_waste_total ~ 1 + 
                                    pdq(0,0,4) + 
                                    PDQ(1,0,0, 
                                        period = 12)))
        
zoo_arima004_100_seasonalfit <- arima(DSNY_NYC_zoo_ts, 
                          order = 1 + c(0,0,4),
                          seasonal = list(order = c(1, 0L, 0L), 
                                          period = 12))
#names(zoo_arima000_fit)
res_arima004_100 <- zoo_arima004_100_seasonalfit$residuals
acf(res_arima004_100, lag.max = 36)
pacf(res_arima004_100, lag.max = 36)
accuracy(nyc_arima004_100_seasonal_fit_cons)[4]
```

RMSE = 13926.64. Most of the lags are now bounded between -0.15 and 0.15. In the PACF, the first significant lag is lag = 9, which is barely significant and negative. Lag = 12 is also significant. 

we can also work with the differenced values, we will create some models with them

## $\text{ARIMA(0,1,0)}$ with constant

${ARIMA(0,1,0)}$

```{r}
nyc_arima010_fit_cons <- nyc_ts_2 %>% 
  model(arima010_constant = ARIMA(total_waste_total ~ 1 + pdq(0,1,0)))

zoo_arima010_fit <- arima(DSNY_NYC_zoo_ts, 
                          order = 1 + c(0,1,0))

res_arima010 <- zoo_arima010_fit$residuals
acf(res_arima010, lag.max = 36)
pacf(res_arima010, lag.max = 36)
accuracy(nyc_arima010_fit_cons)[4]
```

RMSE = 21209.02. In the ACF plot, the seasonal lags are once again significant. Looking at the PACF, the first significant lag is 4, and is negatively autocorrelated.

## $\text{ARIMA(0,1,4)(1,0,0)}$ with constant and seasonal

${ARIMA(0,1,4)(1,0,0)[12]}$

```{r}
nyc_arima014_100_fit_cons <- nyc_ts_2 %>% 
  model(arima014_100_constant = ARIMA(total_waste_total ~ 1 + 
                                        pdq(0,1,4) + 
                                        PDQ(1,0,0, 
                                            period = 12)))

zoo_arima014_100_fit <- arima(DSNY_NYC_zoo_ts, 
                              order = 1 + c(0,1,4),
                              seasonal = list(order = c(1,0L,0L),
                                              period = 12))
res_arima014_100 <- zoo_arima014_100_fit$residuals
acf(res_arima014_100, lag.max = 36)
pacf(res_arima014_100, lag.max = 36)
accuracy(nyc_arima014_100_fit_cons)[4]
```

RMSE = 13816.72. In both plots, lag = 11. Is the lag that is the most autocorrelated.
The RMSE has decreasaed when compared to $ARIMA(0,0,4)(1,0,0)_{12}$

## Auto-arima 

For our final model, we will look and compare the results of an auto-arima model from the feasts package.

```{r}
nyc_auto_arima_fit_cons <- nyc_ts_2 %>% 
  model(stepwise = ARIMA(total_waste_total),
        search = ARIMA(total_waste_total, 
                       stepwise = FALSE, 
                       approximation = FALSE))

accuracy(nyc_auto_arima_fit_cons)[1:4]
```

The stepwise model has RMSE = 16493.55, while the search model has RMSE = 16990.13. We will take a look at the ACF and PACF plots of the stepwise model.

```{r}
nyc_auto_arima_fit_cons %>% select(.model = stepwise) %>% report()
# print("--------------")
# nyc_auto_arima_fit_cons %>% select(.model = search) %>% report()
```

The AICc, AIC, BIC metrics for the stepwise model is barely greater than the metrics for the search model. 

## $\text{ARIMA(2,1,4)}$ with constant from auto-arima

${ARIMA(2,1,4)}$

```{r}
nyc_arima214_fit_cons <- nyc_ts_2 %>% 
  model(arima214_constant = ARIMA(total_waste_total ~ 1 + 
                                        pdq(2,1,4)))

zoo_arima214_fit <- arima(DSNY_NYC_zoo_ts, 
                              order = 1 + c(2,1,4))

res_arima214 <- zoo_arima214_fit$residuals
acf(res_arima214, lag.max = 36)
pacf(res_arima214, lag.max = 36)
accuracy(nyc_arima214_fit_cons)[4]
```

# Summary of total waste ARIMA Models
\
$ARIMA(0,0,4)(1,0,0)[12]$ has RMSE = 13926 \
${ARIMA(0,1,4)(1,0,0)[12]}$ has RMSE = 13816 \ 
${ARIMA(2,1,4)}$ is the step model and has RMSE = 16936.99 

# Dynamic Regression models with ARIMA models from before
\
## $text{ARIMA(0,0,4)(1,0,0)[12]}$
\
```{r}
dr_diff_cons_fit1 <- nyc_ts_2 %>% 
  model(dynam_regress_diff1 = ARIMA(tw_diff1 ~ 1 + cpi_diff1 + unemp_diff1 + 
                avg_precip_diff1 + temp_diff1 + 
                cdd_diff1 +
                trend() +
                pdq(0,0,4) + 
                PDQ(1,0,0,
                    period = 12)))

report(dr_diff_cons_fit1)
accuracy(dr_diff_cons_fit1)
```
When adding the trend() argument, the coefficients of the majority of the predictors and arima errors decrease. 


```{r}
  bind_rows(
    `Regression residuals` =
        as_tibble(residuals(dr_diff_cons_fit1, type = "regression")),
    `ARIMA residuals` =
        as_tibble(residuals(dr_diff_cons_fit1, type = "innovation")),
    .id = "type"
  ) %>%
  mutate(
    type = factor(type, levels=c(
      "Regression residuals", "ARIMA residuals"))
  ) %>%
  ggplot(aes(x = month_num, y = .resid)) +
  geom_line() +
  facet_grid(vars(type)) + 
  labs(title = "Regression Residuals of LM w/ ARIMA(0,0,4)(1,0,0)[12] errors",
       subtitle = "01/2005 - 12/2020",
       x = "Month Number",
       y = "Residuals")
```


```{r}
nyc_data_small_future_diff <- new_data(nyc_ts_2,4) %>% 
  mutate(cpi_diff1 = c(825.413,111, 831.067, 836.885),
         unemp_diff1 = c(0.1333,0.1280, 0.1130, 0.1090),
         avg_precip_diff1 = c(0.07, 0.18, 0.17, 0.12),
         temp_diff1 = c(-4.4, -0.6, 11.6, 8.8),
         cdd_diff1 = c(0,0,0.1, 0.1))
```

```{r}
forecast(dr_diff_cons_fit1, new_data = nyc_data_small_future_diff) %>% 
  autoplot(nyc_ts_1) +
  labs(x  = "Month Number",
       y = "Differenced Total Tonnage",
       title = "Forecasts of LM w/ ARIMA(0,0,4)(1,0,0)[12] errors",
       subtitle = "Jan '05 - Dec '20")
```


## ${ARIMA(0,1,4)(1,0,0)[12]}$

```{r}
dr_diff_cons_fit2 <- nyc_ts_2 %>% 
  model(dynam_regress_diff2 = ARIMA(tw_diff1 ~ 1 + cpi_diff1 + unemp_diff1 + 
                avg_precip_diff1 + temp_diff1 + 
                cdd_diff1 +
                pdq(0,1,4) + 
                PDQ(1,0,0,
                    period = 12)))

report(dr_diff_cons_fit2)
accuracy(dr_diff_cons_fit2)
```

Was given an error: Warning: Provided exogenous regressors are rank deficient, removing regressors: `trend()`
Warning: 1 error encountered for dynam_regress_diff2
[1] system is computationally singular: reciprocal condition number = 2.10254e-16

https://stats.stackexchange.com/questions/76488/error-system-is-computationally-singular-when-running-a-glm

## $\text{{ARIMA(2,1,4)}}$

```{r}
dr_diff_cons_fit3 <- nyc_ts_2 %>% 
  model(dynam_regress_diff3 = ARIMA(tw_diff1 ~ 1 + cpi_diff1 + unemp_diff1 + 
                avg_precip_diff1 + temp_diff1 +
                cdd_diff1 +
                pdq(2,1,4)))

report(dr_diff_cons_fit3)
accuracy(dr_diff_cons_fit3)
```

When including the trend() parameter, I get this error: Warning: Provided exogenous regressors are rank deficient, removing regressors: `trend()`
And this error is also returned:
Warning in sqrt(diag(best$var.coef)) : NaNs produced

```{r}
  bind_rows(
    `Regression residuals` =
        as_tibble(residuals(dr_diff_cons_fit3, type = "regression")),
    `ARIMA residuals` =
        as_tibble(residuals(dr_diff_cons_fit3, type = "innovation")),
    .id = "type"
  ) %>%
  mutate(
    type = factor(type, levels=c(
      "Regression residuals", "ARIMA residuals"))
  ) %>%
  ggplot(aes(x = month_num, y = .resid)) +
  geom_line() +
  facet_grid(vars(type)) + 
  labs(title = "Regression Residuals of LM w/ ARIMA(2,1,4) errors",
       subtitle = "01/2005 - 12/2020",
       x = "Month Number",
       y = "Residuals")
```


```{r}
forecast(dr_diff_cons_fit3, new_data = nyc_data_small_future_diff) %>% 
  autoplot(nyc_ts_1) +
  labs(x  = "Month Number",
       y = "Differenced Total Tonnage",
       title = "Forecasts of LM w/ ARIMA(2,1,4) errors",
       subtitle = "01/2005 - 12/2020")
```

# Summary of Dynamic Regression models
LM w/ ARIMA(5,0,0) errors has AICc=4198.5 \
LM w/ ARIMA(0,0,4)(1,0,0)[12] errors has RMSE = 11339.34 and AICc=4145.17 \
LM w/ ARIMA(0,1,4)(1,0,0)[12] does not give us a output \
LM w/ ARIMA(2,1,4) errors has RMSE = 13979.22 and AICc = 4208.78
